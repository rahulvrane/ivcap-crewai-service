{
  "$schema": "urn:sd-core:schema.crewai.request.1",
  "name": "analysis-with-knowledge",
  "crew": {
    "$schema": "urn:sd:schema.icrew.crew.2",
    "name": "Knowledge-Enhanced Analysis Crew",
    "placeholders": ["topic", "focus_area"],
    "agents": [
      {
        "name": "research_analyst",
        "role": "Research Analyst",
        "goal": "Analyze {topic} with focus on {focus_area}, leveraging previous research findings from knowledge sources",
        "backstory": "You are an expert research analyst with deep knowledge synthesis capabilities. You excel at connecting insights from previous research with current analysis needs. You always reference and build upon existing knowledge when available.",
        "llm": "?llmodel",
        "max_iter": 15,
        "verbose": true,
        "memory": true,
        "tools": [],
        "allow_delegation": false
      },
      {
        "name": "synthesis_writer",
        "role": "Synthesis & Report Writer",
        "goal": "Create a comprehensive synthesis report on {topic} that integrates previous research findings with new analysis",
        "backstory": "You are a skilled technical writer who excels at synthesizing complex information from multiple sources. You create clear, well-structured reports that properly cite and build upon previous research.",
        "llm": "?llmodel",
        "max_iter": 12,
        "verbose": true,
        "memory": true,
        "tools": [],
        "allow_delegation": false
      }
    ],
    "tasks": [
      {
        "name": "analyze_with_context",
        "description": "Conduct analysis of {topic} focusing on {focus_area}. IMPORTANT: Review the knowledge sources for relevant previous research. Your analysis should:\n1. Reference key findings from previous research\n2. Build upon existing insights\n3. Identify gaps or new angles not covered in previous work\n4. Provide fresh perspectives while acknowledging prior findings\n5. Cite specific insights from the knowledge sources when relevant",
        "expected_output": "A detailed analysis (500-1000 words) that:\n- Summarizes relevant findings from previous research\n- Presents new analysis on {topic} and {focus_area}\n- Explicitly references insights from knowledge sources\n- Identifies connections between prior work and current analysis\n- Highlights gaps or new directions\n\nValidation Rules:\n- Must reference at least 2-3 insights from previous research\n- Must clearly distinguish between prior findings and new analysis\n- Must be well-structured with clear sections",
        "agent": "research_analyst",
        "async_execution": false
      },
      {
        "name": "synthesize_report",
        "description": "Create a comprehensive synthesis report that combines the analysis from the previous task with insights from knowledge sources. The report should:\n1. Provide an executive summary\n2. Present a unified narrative connecting previous research and new analysis\n3. Include proper citations to knowledge sources\n4. Conclude with key takeaways and recommendations",
        "expected_output": "A polished synthesis report (800-1500 words) with:\n\n# Executive Summary\nKey findings and connections between prior research and current analysis\n\n# Previous Research Context\nSummary of relevant insights from knowledge sources\n\n# Current Analysis\nDetailed analysis from the research analyst\n\n# Synthesis & Connections\nHow current analysis builds upon, confirms, or challenges previous findings\n\n# Key Takeaways\nMain insights and their implications\n\n# Recommendations\nSuggested next steps or areas for further investigation\n\nValidation Rules:\n- Must properly reference previous research findings\n- Must integrate insights from both knowledge sources and current analysis\n- Must be well-structured and readable\n- Must provide clear value-add beyond just summarizing",
        "agent": "synthesis_writer",
        "context": ["analyze_with_context"],
        "async_execution": false
      }
    ],
    "verbose": true,
    "process": "sequential"
  },
  "inputs": {
    "topic": "AI Safety Alignment",
    "focus_area": "scalable oversight mechanisms"
  },
  "additional-inputs": [
    "# Deep Research on AI Safety\n\n## Executive Summary\n\nThis comprehensive research examined current approaches to AI safety, with particular focus on alignment challenges in large language models. Key findings indicate that constitutional AI and reinforcement learning from human feedback (RLHF) show promise but face scalability limitations.\n\n## Key Findings\n\n### Alignment Techniques\n\n1. **Constitutional AI**: Shows 73% improvement in value alignment but requires extensive prompt engineering\n2. **RLHF**: Effective for narrow domains but struggles with edge cases and adversarial inputs\n3. **Interpretability Methods**: Circuit analysis provides insights but remains computationally expensive\n\n### Identified Challenges\n\n- **Scalability**: Current oversight methods don't scale to very large models (>100B parameters)\n- **Robustness**: Models show brittleness when faced with distribution shifts\n- **Value Specification**: Difficulty in precisely specifying human values in machine-readable format\n\n## Research Gaps\n\n1. Lack of standardized evaluation frameworks for alignment\n2. Limited understanding of emergent capabilities in scaled models\n3. Need for more robust oversight mechanisms\n\n## Recommendations\n\nFuture research should focus on:\n- Developing automated alignment evaluation systems\n- Exploring decentralized oversight approaches\n- Investigating formal verification methods for AI systems",
    "# Expert Profiles in AI Safety\n\n## Leading Researchers\n\n### Dr. Sarah Chen - UC Berkeley\n**Expertise**: Scalable oversight, formal verification\n**Key Contributions**: \n- Developed recursive reward modeling framework\n- Published 23 papers on AI alignment (h-index: 34)\n- Leading CHAI (Center for Human-Compatible AI)\n\n**Current Focus**: Investigating debate-based oversight mechanisms for superhuman AI systems\n\n### Dr. Michael Torres - DeepMind\n**Expertise**: Constitutional AI, value learning\n**Key Contributions**:\n- Co-author of Constitutional AI paper (12,000+ citations)\n- Led development of helpful, harmless, honest (HHH) evaluation framework\n- Advisor to multiple AI safety initiatives\n\n**Current Focus**: Scaling constitutional AI to multimodal systems\n\n### Prof. Amara Okafor - MIT CSAIL\n**Expertise**: Interpretability, mechanistic understanding\n**Key Contributions**:\n- Pioneer in neural network circuit analysis\n- Developed \"attention head archaeology\" methodology\n- 50+ publications on AI safety and interpretability\n\n**Current Focus**: Building tools for automated circuit discovery in transformer models\n\n## Key Organizations\n\n1. **Anthropic**: Leading constitutional AI and scaling law research\n2. **Alignment Research Center (ARC)**: Focus on evaluating dangerous capabilities\n3. **Redwood Research**: Developing adversarial training techniques\n4. **AI Safety Institute (AISI)**: Government-affiliated safety evaluation\n\n## Emerging Researchers\n\nSeveral early-career researchers show promise:\n- Dr. Jun Li (Stanford): Debate protocols for oversight\n- Emma Rodriguez (Oxford): Formal methods for value alignment\n- Dr. Raj Patel (Carnegie Mellon): Scalable interpretability techniques"
  ]
}

